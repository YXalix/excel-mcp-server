#!/usr/bin/env python3
"""
å¹¶å‘ Excel MCP æœåŠ¡å™¨å®¢æˆ·ç«¯å®ç°

æ”¯æŒä»¥ä¸‹åŠŸèƒ½:
1. å¹¶å‘è¿æ¥å¤šä¸ªå®¢æˆ·ç«¯
2. å¹¶å‘æ‰§è¡Œå¤šä¸ªè¯·æ±‚
3. è®°å½•æ¯ä¸ªè¯·æ±‚çš„æ—¶å»¶
4. ç»Ÿè®¡åˆ†æå¹¶å‘æ€§èƒ½

ä½¿ç”¨æ–¹æ³•:
1. ç¡®ä¿ Excel MCP æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: uvx excel-mcp-server streamable-http
2. è¿è¡Œæ­¤è„šæœ¬: python concurrent_excel_mcp_client.py

ä½œè€…: åŸºäºåŸ excel_mcp_client.py æ‰©å±•
"""

import asyncio
import aiohttp
import json
import time
import statistics
import psutil
import os
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass
from datetime import datetime
import concurrent.futures
import threading


@dataclass
class RequestMetrics:
    """è¯·æ±‚æŒ‡æ ‡æ•°æ®"""
    request_id: str
    method: str
    start_time: float
    end_time: float
    duration: float
    success: bool
    error: Optional[str] = None


@dataclass
class SystemMetrics:
    """ç³»ç»Ÿèµ„æºä½¿ç”¨æŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    io_read_bytes: int
    io_write_bytes: int
    io_read_count: int
    io_write_count: int


@dataclass 
class ResourceStats:
    """èµ„æºç»Ÿè®¡æ•°æ®"""
    start_metrics: SystemMetrics
    end_metrics: SystemMetrics
    peak_cpu: float
    peak_memory: float
    total_io_read: int
    total_io_write: int


class SystemResourceMonitor:
    """ç³»ç»Ÿèµ„æºç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.monitoring = False
        self.metrics_history: List[SystemMetrics] = []
        self._monitor_task = None
        
    def get_current_metrics(self) -> SystemMetrics:
        """è·å–å½“å‰ç³»ç»ŸæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = self.process.cpu_percent()
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_info = self.process.memory_info()
        memory_percent = self.process.memory_percent()
        memory_used_mb = memory_info.rss / 1024 / 1024
        
        # IOä½¿ç”¨æƒ…å†µ (å¯èƒ½ä¸åœ¨æ‰€æœ‰å¹³å°ä¸Šå¯ç”¨)
        io_read_bytes = 0
        io_write_bytes = 0
        io_read_count = 0
        io_write_count = 0
        
        try:
            if hasattr(self.process, 'io_counters'):
                io_counters = getattr(self.process, 'io_counters')()
                io_read_bytes = io_counters.read_bytes
                io_write_bytes = io_counters.write_bytes
                io_read_count = io_counters.read_count
                io_write_count = io_counters.write_count
        except (AttributeError, OSError, PermissionError):
            # å¦‚æœIOè®¡æ•°å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨0
            pass
        
        return SystemMetrics(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory_percent,
            memory_used_mb=memory_used_mb,
            io_read_bytes=io_read_bytes,
            io_write_bytes=io_write_bytes,
            io_read_count=io_read_count,
            io_write_count=io_write_count
        )
    
    async def start_monitoring(self, interval: float = 0.1):
        """å¼€å§‹ç›‘æ§ç³»ç»Ÿèµ„æº"""
        self.monitoring = True
        self.metrics_history = []
        
        async def monitor_loop():
            while self.monitoring:
                try:
                    metrics = self.get_current_metrics()
                    self.metrics_history.append(metrics)
                    await asyncio.sleep(interval)
                except Exception as e:
                    print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    break
        
        self._monitor_task = asyncio.create_task(monitor_loop())
    
    async def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self._monitor_task:
            await self._monitor_task
    
    def get_resource_stats(self) -> Optional[ResourceStats]:
        """è·å–èµ„æºç»Ÿè®¡ä¿¡æ¯"""
        if len(self.metrics_history) < 2:
            return None
        
        start_metrics = self.metrics_history[0]
        end_metrics = self.metrics_history[-1]
        
        # è®¡ç®—å³°å€¼
        peak_cpu = max(m.cpu_percent for m in self.metrics_history)
        peak_memory = max(m.memory_percent for m in self.metrics_history)
        
        # è®¡ç®—æ€»IO
        total_io_read = end_metrics.io_read_bytes - start_metrics.io_read_bytes
        total_io_write = end_metrics.io_write_bytes - start_metrics.io_write_bytes
        
        return ResourceStats(
            start_metrics=start_metrics,
            end_metrics=end_metrics,
            peak_cpu=peak_cpu,
            peak_memory=peak_memory,
            total_io_read=total_io_read,
            total_io_write=total_io_write
        )


class ConcurrentExcelMCPClient:
    """æ”¯æŒå¹¶å‘çš„ Excel MCP æœåŠ¡å™¨å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:8000", client_id: Optional[str] = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            base_url: MCP æœåŠ¡å™¨åŸºç¡€ URL
            client_id: å®¢æˆ·ç«¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„å¹¶å‘å®¢æˆ·ç«¯
        """
        self.base_url = base_url
        self.mcp_url = f"{base_url}/mcp"
        self.client_id = client_id or f"client_{threading.current_thread().ident}"
        self.session_id: Optional[str] = None
        self.session: Optional[aiohttp.ClientSession] = None
        self._id_counter = 1
        self.metrics: List[RequestMetrics] = []
        self.resource_monitor = SystemResourceMonitor()
        self._lock = threading.Lock()

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()

    def _get_next_id(self) -> int:
        """è·å–ä¸‹ä¸€ä¸ªè¯·æ±‚ ID"""
        with self._lock:
            self._id_counter += 1
            return self._id_counter

    def _record_metric(self, request_id: str, method: str, start_time: float, 
                      end_time: float, success: bool, error: Optional[str] = None):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        duration = end_time - start_time
        metric = RequestMetrics(
            request_id=request_id,
            method=method,
            start_time=start_time,
            end_time=end_time,
            duration=duration,
            success=success,
            error=error
        )
        with self._lock:
            self.metrics.append(metric)

    async def connect(self) -> bool:
        """
        è¿æ¥åˆ° MCP æœåŠ¡å™¨å¹¶å®Œæˆåˆå§‹åŒ–æµç¨‹
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸè¿æ¥
        """
        print(f"ğŸ”„ å®¢æˆ·ç«¯ {self.client_id} æ­£åœ¨è¿æ¥åˆ° Excel MCP æœåŠ¡å™¨...")
        
        # ç¬¬ä¸€æ­¥ï¼šåˆå§‹åŒ–ä¼šè¯
        if not await self._initialize():
            return False
        
        # ç¬¬äºŒæ­¥ï¼šå‘é€ initialized é€šçŸ¥
        if not await self._send_initialized():
            return False
        
        print(f"âœ… å®¢æˆ·ç«¯ {self.client_id} æˆåŠŸè¿æ¥åˆ° Excel MCP æœåŠ¡å™¨")
        return True

    async def _initialize(self) -> bool:
        """å‘é€åˆå§‹åŒ–è¯·æ±‚"""
        start_time = time.time()
        request_id = f"{self.client_id}_init_{self._get_next_id()}"
        
        payload = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "initialize",
            "params": {
                "protocolVersion": "2024-11-05",
                "capabilities": {
                    "roots": {"listChanged": True},
                    "sampling": {}
                },
                "clientInfo": {
                    "name": f"concurrent-python-excel-mcp-client-{self.client_id}",
                    "version": "1.0.0"
                }
            }
        }

        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json,text/event-stream"
        }

        try:
            if not self.session:
                raise RuntimeError("Session not initialized")
                
            async with self.session.post(self.mcp_url, json=payload, headers=headers) as response:
                end_time = time.time()
                
                if response.status != 200:
                    error_msg = f"åˆå§‹åŒ–å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                    print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
                    self._record_metric(request_id, "initialize", start_time, end_time, False, error_msg)
                    return False
                
                # è·å– session ID
                session_id = response.headers.get('mcp-session-id')
                if not session_id:
                    error_msg = "æœªè·å–åˆ° session ID"
                    print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
                    self._record_metric(request_id, "initialize", start_time, end_time, False, error_msg)
                    return False
                
                self.session_id = session_id
                self._record_metric(request_id, "initialize", start_time, end_time, True)
                print(f"âœ… å®¢æˆ·ç«¯ {self.client_id} è·å–åˆ° session ID: {session_id}")
                return True

        except Exception as e:
            end_time = time.time()
            error_msg = f"åˆå§‹åŒ–è¯·æ±‚å¤±è´¥: {e}"
            print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
            self._record_metric(request_id, "initialize", start_time, end_time, False, error_msg)
            return False

    async def _send_initialized(self) -> bool:
        """å‘é€ initialized é€šçŸ¥"""
        if not self.session_id:
            print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: æ²¡æœ‰æœ‰æ•ˆçš„ session ID")
            return False
        
        start_time = time.time()
        request_id = f"{self.client_id}_initialized_{self._get_next_id()}"
        
        payload = {
            "jsonrpc": "2.0",
            "method": "notifications/initialized"
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json,text/event-stream",
            "mcp-session-id": self.session_id
        }
        
        try:
            if not self.session:
                raise RuntimeError("Session not initialized")
                
            async with self.session.post(self.mcp_url, json=payload, headers=headers) as response:
                end_time = time.time()
                self._record_metric(request_id, "notifications/initialized", start_time, end_time, True)
                return True
                
        except Exception as e:
            end_time = time.time()
            error_msg = f"å‘é€ initialized é€šçŸ¥å¤±è´¥: {e}"
            print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
            self._record_metric(request_id, "notifications/initialized", start_time, end_time, False, error_msg)
            return False

    async def list_tools(self) -> Optional[Dict]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·
        
        Returns:
            Dict: åŒ…å«å·¥å…·åˆ—è¡¨çš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        return await self._call_method("tools/list", {})

    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Optional[Any]:
        """
        è°ƒç”¨æŒ‡å®šçš„å·¥å…·
        
        Args:
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            
        Returns:
            Any: å·¥å…·è¿”å›ç»“æœï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        params = {
            "name": tool_name,
            "arguments": arguments
        }

        result = await self._call_method("tools/call", params)
        
        if result and "structuredContent" in result:
            return result["structuredContent"]["result"]
        elif result and "content" in result:
            # å¤„ç†è¿”å›å†…å®¹
            content = result["content"]
            if isinstance(content, list) and len(content) > 0:
                return content[0].get("text", "")
            return content
        
        return result

    async def _call_method(self, method: str, params: Dict[str, Any]) -> Optional[Dict]:
        """
        è°ƒç”¨ MCP æ–¹æ³•
        
        Args:
            method: æ–¹æ³•å
            params: å‚æ•°
            
        Returns:
            Dict: å“åº”ç»“æœ
        """
        if not self.session_id:
            print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: æ²¡æœ‰æœ‰æ•ˆçš„ session IDï¼Œè¯·å…ˆè°ƒç”¨ connect()")
            return None
        
        start_time = time.time()
        request_id = f"{self.client_id}_{method}_{self._get_next_id()}"
        
        payload = {
            "jsonrpc": "2.0",
            "id": self._get_next_id(),
            "method": method,
            "params": params
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json,text/event-stream",
            "mcp-session-id": self.session_id
        }
        
        try:
            if not self.session:
                raise RuntimeError("Session not initialized")
                
            async with self.session.post(self.mcp_url, json=payload, headers=headers) as response:
                end_time = time.time()
                
                if response.status != 200:
                    error_msg = f"æ–¹æ³•è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                    print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
                    self._record_metric(request_id, method, start_time, end_time, False, error_msg)
                    return None
                
                # è§£æ SSE å“åº”
                response_text = await response.text()
                if response_text.startswith('event:'):
                    lines = response_text.strip().split('\n')
                    for line in lines:
                        if line.startswith('data:'):
                            try:
                                data = json.loads(line[5:].strip())
                                if 'result' in data:
                                    self._record_metric(request_id, method, start_time, end_time, True)
                                    return data['result']
                                elif 'error' in data:
                                    error_msg = f"æœåŠ¡å™¨é”™è¯¯: {data['error']}"
                                    print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
                                    self._record_metric(request_id, method, start_time, end_time, False, error_msg)
                                    return None
                            except json.JSONDecodeError:
                                pass
                
                error_msg = "æ— æ³•è§£æå“åº”"
                self._record_metric(request_id, method, start_time, end_time, False, error_msg)
                return None
                
        except Exception as e:
            end_time = time.time()
            error_msg = f"æ–¹æ³•è°ƒç”¨å¼‚å¸¸: {e}"
            print(f"âŒ å®¢æˆ·ç«¯ {self.client_id}: {error_msg}")
            self._record_metric(request_id, method, start_time, end_time, False, error_msg)
            return None

    # ä¾¿æ·æ–¹æ³•
    async def read_excel_data(self, filepath: str, sheet_name: str, start_cell: str = "A1", 
                             end_cell: Optional[str] = None) -> Optional[str]:
        """è¯»å– Excel æ•°æ®"""
        arguments = {
            "filepath": filepath,
            "sheet_name": sheet_name,
            "start_cell": start_cell
        }
        
        if end_cell:
            arguments["end_cell"] = end_cell
        
        return await self.call_tool("read_data_from_excel", arguments)

    async def get_workbook_metadata(self, filepath: str, include_ranges: bool = False) -> Optional[str]:
        """è·å–å·¥ä½œç°¿å…ƒæ•°æ®"""
        arguments = {
            "filepath": filepath,
            "include_ranges": include_ranges
        }
        return await self.call_tool("get_workbook_metadata", arguments)

    def get_metrics_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡æ‘˜è¦"""
        if not self.metrics:
            return {"message": "æ²¡æœ‰æŒ‡æ ‡æ•°æ®"}
        
        successful_metrics = [m for m in self.metrics if m.success]
        failed_metrics = [m for m in self.metrics if not m.success]
        
        durations = [m.duration for m in successful_metrics]
        
        summary = {
            "client_id": self.client_id,
            "total_requests": len(self.metrics),
            "successful_requests": len(successful_metrics),
            "failed_requests": len(failed_metrics),
            "success_rate": len(successful_metrics) / len(self.metrics) * 100 if self.metrics else 0,
        }
        
        if durations:
            summary.update({
                "avg_duration_ms": statistics.mean(durations) * 1000,
                "min_duration_ms": min(durations) * 1000,
                "max_duration_ms": max(durations) * 1000,
                "median_duration_ms": statistics.median(durations) * 1000,
            })
            
            if len(durations) > 1:
                summary["std_duration_ms"] = statistics.stdev(durations) * 1000
        
        # æ·»åŠ èµ„æºä½¿ç”¨ç»Ÿè®¡
        resource_stats = self.resource_monitor.get_resource_stats()
        if resource_stats:
            summary.update({
                "resource_usage": {
                    "peak_cpu_percent": resource_stats.peak_cpu,
                    "peak_memory_percent": resource_stats.peak_memory,
                    "start_memory_mb": resource_stats.start_metrics.memory_used_mb,
                    "end_memory_mb": resource_stats.end_metrics.memory_used_mb,
                    "memory_delta_mb": resource_stats.end_metrics.memory_used_mb - resource_stats.start_metrics.memory_used_mb,
                    "total_io_read_bytes": resource_stats.total_io_read,
                    "total_io_write_bytes": resource_stats.total_io_write,
                    "avg_cpu_percent": statistics.mean([m.cpu_percent for m in self.resource_monitor.metrics_history]) if self.resource_monitor.metrics_history else 0,
                    "avg_memory_percent": statistics.mean([m.memory_percent for m in self.resource_monitor.metrics_history]) if self.resource_monitor.metrics_history else 0,
                }
            })
        
        return summary


class ConcurrencyManager:
    """å¹¶å‘ç®¡ç†å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.all_metrics: List[RequestMetrics] = []
        self.global_resource_monitor = SystemResourceMonitor()

    async def run_concurrent_clients(self, num_clients: int, operations_per_client: int) -> List[Dict[str, Any]]:
        """
        è¿è¡Œå¹¶å‘å®¢æˆ·ç«¯
        
        Args:
            num_clients: å¹¶å‘å®¢æˆ·ç«¯æ•°é‡
            operations_per_client: æ¯ä¸ªå®¢æˆ·ç«¯æ‰§è¡Œçš„æ“ä½œæ•°é‡
            
        Returns:
            List[Dict]: æ¯ä¸ªå®¢æˆ·ç«¯çš„æ€§èƒ½æŒ‡æ ‡æ‘˜è¦
        """
        print(f"ğŸš€ å¯åŠ¨ {num_clients} ä¸ªå¹¶å‘å®¢æˆ·ç«¯ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯æ‰§è¡Œ {operations_per_client} ä¸ªæ“ä½œ...")
        
        # å¼€å§‹å…¨å±€èµ„æºç›‘æ§
        await self.global_resource_monitor.start_monitoring(interval=0.1)
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i in range(num_clients):
            client_id = f"client_{i+1}"
            task = self._run_single_client(client_id, operations_per_client)
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()
        
        # åœæ­¢å…¨å±€èµ„æºç›‘æ§
        await self.global_resource_monitor.stop_monitoring()
        
        # å¤„ç†ç»“æœ
        summaries = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"âŒ å®¢æˆ·ç«¯ {i+1} æ‰§è¡Œå¤±è´¥: {result}")
                summaries.append({"client_id": f"client_{i+1}", "error": str(result)})
            else:
                summaries.append(result)
                # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
                if isinstance(result, dict) and "metrics" in result:
                    self.all_metrics.extend(result["metrics"])
        
        print(f"âœ… æ‰€æœ‰å¹¶å‘å®¢æˆ·ç«¯æ‰§è¡Œå®Œæ¯•ï¼Œæ€»ç”¨æ—¶: {end_time - start_time:.2f} ç§’")
        return summaries

    async def _run_single_client(self, client_id: str, num_operations: int) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå®¢æˆ·ç«¯"""
        async with ConcurrentExcelMCPClient(self.base_url, client_id) as client:
            # å¼€å§‹èµ„æºç›‘æ§
            await client.resource_monitor.start_monitoring(interval=0.1)
            
            # è¿æ¥åˆ°æœåŠ¡å™¨
            if not await client.connect():
                await client.resource_monitor.stop_monitoring()
                return {"client_id": client_id, "error": "è¿æ¥å¤±è´¥"}
            
            # æ‰§è¡Œå¤šä¸ªæ“ä½œ
            tasks = []
            for i in range(num_operations):
                if i % 3 == 0:
                    # è¯»å– Excel æ•°æ®
                    task = client.read_excel_data(
                        "/Users/nashzhou/code/openhands/excel-mcp-server/small.xlsx",
                        "Sheet",
                        "A1"
                    )
                elif i % 3 == 1:
                    # è·å–å·¥ä½œç°¿å…ƒæ•°æ®
                    task = client.get_workbook_metadata(
                        "/Users/nashzhou/code/openhands/excel-mcp-server/large.xlsx"
                    )
                else:
                    # åˆ—å‡ºå·¥å…·
                    task = client.list_tools()
                
                tasks.append(task)
            
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ“ä½œ
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # åœæ­¢èµ„æºç›‘æ§
            await client.resource_monitor.stop_monitoring()
            
            # è·å–æ€§èƒ½æŒ‡æ ‡
            summary = client.get_metrics_summary()
            summary["metrics"] = client.metrics
            return summary

    def print_overall_statistics(self, summaries: List[Dict[str, Any]]):
        """æ‰“å°æ€»ä½“ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ“Š å¹¶å‘æ€§èƒ½ç»Ÿè®¡")
        print("="*80)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_clients = len([s for s in summaries if "error" not in s])
        failed_clients = len([s for s in summaries if "error" in s])
        
        print(f"æ€»å®¢æˆ·ç«¯æ•°é‡: {len(summaries)}")
        print(f"æˆåŠŸå®¢æˆ·ç«¯æ•°é‡: {total_clients}")
        print(f"å¤±è´¥å®¢æˆ·ç«¯æ•°é‡: {failed_clients}")
        
        if total_clients == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®¢æˆ·ç«¯")
            return
        
        # èšåˆæŒ‡æ ‡
        total_requests = sum(s.get("total_requests", 0) for s in summaries if "error" not in s)
        successful_requests = sum(s.get("successful_requests", 0) for s in summaries if "error" not in s)
        failed_requests = sum(s.get("failed_requests", 0) for s in summaries if "error" not in s)
        
        print(f"\nè¯·æ±‚ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"  æˆåŠŸè¯·æ±‚æ•°: {successful_requests}")
        print(f"  å¤±è´¥è¯·æ±‚æ•°: {failed_requests}")
        print(f"  æ€»ä½“æˆåŠŸç‡: {successful_requests/total_requests*100:.1f}%" if total_requests > 0 else "  æ€»ä½“æˆåŠŸç‡: 0%")
        
        # æ—¶å»¶ç»Ÿè®¡
        if self.all_metrics:
            successful_durations = [m.duration * 1000 for m in self.all_metrics if m.success]
            
            if successful_durations:
                print(f"\næ—¶å»¶ç»Ÿè®¡ (æ¯«ç§’):")
                print(f"  å¹³å‡æ—¶å»¶: {statistics.mean(successful_durations):.2f}")
                print(f"  æœ€å°æ—¶å»¶: {min(successful_durations):.2f}")
                print(f"  æœ€å¤§æ—¶å»¶: {max(successful_durations):.2f}")
                print(f"  ä¸­ä½æ•°æ—¶å»¶: {statistics.median(successful_durations):.2f}")
                if len(successful_durations) > 1:
                    print(f"  æ ‡å‡†å·®: {statistics.stdev(successful_durations):.2f}")
                
                # åˆ†ä½æ•°
                sorted_durations = sorted(successful_durations)
                p95_index = int(len(sorted_durations) * 0.95)
                p99_index = int(len(sorted_durations) * 0.99)
                print(f"  95th åˆ†ä½æ•°: {sorted_durations[p95_index]:.2f}")
                print(f"  99th åˆ†ä½æ•°: {sorted_durations[p99_index]:.2f}")
        
        # èµ„æºä½¿ç”¨ç»Ÿè®¡
        self._print_resource_statistics(summaries)
        
        # å…¨å±€èµ„æºç»Ÿè®¡
        global_resource_stats = self.global_resource_monitor.get_resource_stats()
        if global_resource_stats:
            print(f"\nå…¨å±€èµ„æºä½¿ç”¨:")
            print(f"  å³°å€¼CPUä½¿ç”¨ç‡: {global_resource_stats.peak_cpu:.1f}%")
            print(f"  å³°å€¼å†…å­˜ä½¿ç”¨ç‡: {global_resource_stats.peak_memory:.1f}%")
            print(f"  å†…å­˜ä½¿ç”¨å˜åŒ–: {global_resource_stats.end_metrics.memory_used_mb - global_resource_stats.start_metrics.memory_used_mb:.1f} MB")
            print(f"  æ€»IOè¯»å–: {global_resource_stats.total_io_read:,} å­—èŠ‚")
            print(f"  æ€»IOå†™å…¥: {global_resource_stats.total_io_write:,} å­—èŠ‚")
        
        # æ¯ä¸ªå®¢æˆ·ç«¯çš„è¯¦ç»†ä¿¡æ¯
        print(f"\nå®¢æˆ·ç«¯è¯¦ç»†ä¿¡æ¯:")
        for summary in summaries:
            if "error" in summary:
                print(f"  {summary['client_id']}: âŒ {summary['error']}")
            else:
                avg_duration = summary.get("avg_duration_ms", 0)
                success_rate = summary.get("success_rate", 0)
                total = summary.get("total_requests", 0)
                resource_info = ""
                if "resource_usage" in summary:
                    ru = summary["resource_usage"]
                    resource_info = f", å³°å€¼CPU: {ru.get('peak_cpu_percent', 0):.1f}%, å³°å€¼å†…å­˜: {ru.get('peak_memory_percent', 0):.1f}%"
                print(f"  {summary['client_id']}: {total} è¯·æ±‚, {success_rate:.1f}% æˆåŠŸç‡, {avg_duration:.2f}ms å¹³å‡æ—¶å»¶{resource_info}")
    
    def _print_resource_statistics(self, summaries: List[Dict[str, Any]]):
        """æ‰“å°èµ„æºä½¿ç”¨ç»Ÿè®¡"""
        resource_summaries = [s for s in summaries if "error" not in s and "resource_usage" in s]
        
        if not resource_summaries:
            return
        
        print(f"\nèµ„æºä½¿ç”¨ç»Ÿè®¡:")
        
        # èšåˆèµ„æºæ•°æ®
        peak_cpus = [s["resource_usage"]["peak_cpu_percent"] for s in resource_summaries]
        peak_memories = [s["resource_usage"]["peak_memory_percent"] for s in resource_summaries]
        avg_cpus = [s["resource_usage"]["avg_cpu_percent"] for s in resource_summaries]
        avg_memories = [s["resource_usage"]["avg_memory_percent"] for s in resource_summaries]
        memory_deltas = [s["resource_usage"]["memory_delta_mb"] for s in resource_summaries]
        total_io_reads = [s["resource_usage"]["total_io_read_bytes"] for s in resource_summaries]
        total_io_writes = [s["resource_usage"]["total_io_write_bytes"] for s in resource_summaries]
        
        if peak_cpus:
            print(f"  CPUä½¿ç”¨ç‡ - æœ€å¤§å³°å€¼: {max(peak_cpus):.1f}%, å¹³å‡å³°å€¼: {statistics.mean(peak_cpus):.1f}%")
            print(f"  CPUä½¿ç”¨ç‡ - å¹³å‡ä½¿ç”¨: {statistics.mean(avg_cpus):.1f}%")
        
        if peak_memories:
            print(f"  å†…å­˜ä½¿ç”¨ç‡ - æœ€å¤§å³°å€¼: {max(peak_memories):.1f}%, å¹³å‡å³°å€¼: {statistics.mean(peak_memories):.1f}%")
            print(f"  å†…å­˜ä½¿ç”¨ç‡ - å¹³å‡ä½¿ç”¨: {statistics.mean(avg_memories):.1f}%")
        
        if memory_deltas:
            total_memory_change = sum(memory_deltas)
            print(f"  å†…å­˜å˜åŒ– - æ€»è®¡: {total_memory_change:.1f} MB, å¹³å‡æ¯å®¢æˆ·ç«¯: {statistics.mean(memory_deltas):.1f} MB")
        
        if total_io_reads:
            total_read = sum(total_io_reads)
            total_write = sum(total_io_writes)
            print(f"  IOä½¿ç”¨ - æ€»è¯»å–: {total_read:,} å­—èŠ‚, æ€»å†™å…¥: {total_write:,} å­—èŠ‚")


async def demo_concurrent():
    """å¹¶å‘æ¼”ç¤º"""
    print("ğŸ¯ Excel MCP æœåŠ¡å™¨å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºå¹¶å‘ç®¡ç†å™¨
    manager = ConcurrencyManager()
    
    # æµ‹è¯•ä¸åŒçš„å¹¶å‘çº§åˆ«
    test_configs = [
        (2, 1),   # 2ä¸ªå®¢æˆ·ç«¯ï¼Œæ¯ä¸ª5ä¸ªæ“ä½œ
        # (5, 3),   # 5ä¸ªå®¢æˆ·ç«¯ï¼Œæ¯ä¸ª3ä¸ªæ“ä½œ
        # (10, 100),  # 10ä¸ªå®¢æˆ·ç«¯ï¼Œæ¯ä¸ª100ä¸ªæ“ä½œ
    ]
    
    for num_clients, operations_per_client in test_configs:
        print(f"\nğŸ”¬ æµ‹è¯•é…ç½®: {num_clients} å®¢æˆ·ç«¯ Ã— {operations_per_client} æ“ä½œ")
        print("-" * 60)
        
        # é‡ç½®æŒ‡æ ‡
        manager.all_metrics = []
        
        # è¿è¡Œæµ‹è¯•
        summaries = await manager.run_concurrent_clients(num_clients, operations_per_client)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        manager.print_overall_statistics(summaries)
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´å†è¿›è¡Œä¸‹ä¸€ä¸ªæµ‹è¯•
        await asyncio.sleep(2)


if __name__ == "__main__":
    asyncio.run(demo_concurrent())
